{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Imports and constants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2025-01-21T00:07:14.106694Z",
     "end_time": "2025-01-21T00:07:14.127371Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from general_data_editing import process_excel_multiple_sheets_to_csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "input_file_responses = \"data/FIN-RawData-FindingVulnerabilities-Global_manual-editedV2.xlsx\"  # input file\n",
    "input_file_ground_truth = \"data/FIN-FindingVulnerabilities-GroundTruth_good_to_use.xlsx\"  # input file ground truth\n",
    "input_file_ground_truth_code_lines = \"data/ground_truth_code_lines.xlsx\"\n",
    "responses_step1_file = \"data/responses_step1.csv\"  # .xlsx to csv of respondents\n",
    "responses_step2_file = \"data/responses_step2.csv\"  # Generating first properties"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-01-21T01:39:11.870971Z",
     "end_time": "2025-01-21T01:39:11.870971Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading Excel- and csv files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "process_excel_multiple_sheets_to_csv(input_file_responses, responses_step1_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-01-21T00:59:35.356855Z",
     "end_time": "2025-01-21T00:59:35.884520Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "df_ground_truth = pd.read_excel(input_file_ground_truth)\n",
    "df_gt_code_lines = pd.read_excel(input_file_ground_truth_code_lines)\n",
    "df_responses = pd.read_csv(responses_step1_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-01-21T00:59:35.890520Z",
     "end_time": "2025-01-21T00:59:35.954189Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Groupnr                                               Path  \\\n",
      "0  Group1  [368,383,384,385,386,388, 432, 846, 853, 854, ...   \n",
      "1  Group2  [76, 78, 79, 80, 81, 83, 95, 108, 113, 114, 11...   \n",
      "2  Group3  [76, 78, 79, 80, 81, 83, 95, 108, 113, 114, 11...   \n",
      "3  Group4  [368,383,384,385,386,388, 432, 846, 853, 854, ...   \n",
      "4  Group5  [368,383,384,385,386,388, 432, 846, 853, 854, ...   \n",
      "5  Group6  [76, 78, 79, 80, 81, 83, 95, 108, 113, 114, 11...   \n",
      "\n",
      "                        User                   XSS              DoS  \n",
      "0       [59, 61, 62, 87, 90]  [441, 444, 450, 451]       [48,50,51]  \n",
      "1  [144, 147, 151, 287, 290]      [73, 74, 75, 76]  [459, 462, 463]  \n",
      "2       [59, 61, 62, 87, 90]  [441, 444, 450, 451]  [459, 462, 463]  \n",
      "3  [144, 147, 151, 287, 290]      [73, 74, 75, 76]       [48,50,51]  \n",
      "4       [59, 61, 62, 87, 90]      [73, 74, 75, 76]  [459, 462, 463]  \n",
      "5  [144, 147, 151, 287, 290]  [441, 444, 450, 451]       [48,50,51]  \n",
      "   type                                              slice  \\\n",
      "0  path  [76, 78, 79, 80, 81, 83, 95, 108, 113, 114, 11...   \n",
      "1  user                               [59, 61, 62, 87, 90]   \n",
      "2   xss                                   [73, 74, 75, 76]   \n",
      "3   dos                                         [48,50,51]   \n",
      "\n",
      "                                                full  \n",
      "0  [368,383,384,385,386,388, 432, 846, 853, 854, ...  \n",
      "1                          [144, 147, 151, 287, 290]  \n",
      "2                               [441, 444, 450, 451]  \n",
      "3                                    [459, 462, 463]  \n"
     ]
    }
   ],
   "source": [
    "print(df_ground_truth)\n",
    "print(df_gt_code_lines)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-01-21T00:59:36.574053Z",
     "end_time": "2025-01-21T00:59:36.602900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "difficulties_list = [\"very easy\", \"easy\", \"neither hard nor easy\", \"hard\", \"very hard\"]\n",
    "confidence_list = [\"0-20%\", \"20-40%\", \"40-60%\", \"60-80%\", \"80%-100%\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-01-21T01:21:16.873561Z",
     "end_time": "2025-01-21T01:21:16.894577Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pipeline itself"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "New csv file for responses, more detailed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "columns_for_new_csv = [\n",
    "        'respondent_id',  # Data direct from raw data\n",
    "        'duration_of_experiment',\n",
    "        'which_group',\n",
    "        'exp_coding',\n",
    "        'exp_working_java',\n",
    "        'exp_finding_vuln',\n",
    "        'path_lines',\n",
    "        'path_lines_correctness',\n",
    "        'path_lines_type',\n",
    "        'path_motivation',\n",
    "        'path_difficulty',\n",
    "        'path_confidence',\n",
    "        'userinjection_lines',\n",
    "        'userinjection_lines_correctness',\n",
    "        'userinjection_lines_type',\n",
    "        'userinjection_motivation',\n",
    "        'userinjection_difficulty',\n",
    "        'userinjection_confidence',\n",
    "        'xss_lines',\n",
    "        'xss_lines_correctness',\n",
    "        'xss_lines_type',\n",
    "        'xss_motivation',\n",
    "        'xss_difficulty',\n",
    "        'xss_confidence',\n",
    "        'dos_lines',\n",
    "        'dos_lines_correctness',\n",
    "        'dos_lines_type',\n",
    "        'dos_motivation',\n",
    "        'dos_difficulty',\n",
    "        'dos_confidence',\n",
    "        'familiar_java',\n",
    "        'familiar_vuln',\n",
    "        'proc_understand',\n",
    "        'proc_time',\n",
    "        'proc_training',\n",
    "        'avg_correctness_slice',\n",
    "        'avg_correctness_full'\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-01-21T01:49:32.520363Z",
     "end_time": "2025-01-21T01:49:32.520363Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(columns=columns_for_new_csv)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-01-21T01:49:32.873888Z",
     "end_time": "2025-01-21T01:49:32.873888Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "def calc_lines_correctness(actual_lines: str, lines_raw: str) -> float:\n",
    "    try:\n",
    "        actual_lines_list = list(map(int, actual_lines.strip(\"[\").strip(\"]\").replace(\",\", \" \").split()))\n",
    "\n",
    "        lines_raw_list = list(map(int, filter(None, map(str.strip, lines_raw.replace(\",\", \" \").replace(\"-\",\" \").replace(\":\", \" \").replace(\";\", \" \").split()))))\n",
    "\n",
    "        # Calculate overlap between the two lists\n",
    "        correct_lines = set(actual_lines_list).intersection(set(lines_raw_list))\n",
    "\n",
    "        # Calculate the percentage of matching lines relative to the length of actual_lines_list\n",
    "        correctness = len(correct_lines) / len(actual_lines_list) if actual_lines_list else 0.0\n",
    "\n",
    "        return correctness\n",
    "    except (ValueError, ZeroDivisionError) as e:\n",
    "        # Handle potential conversion errors or division by zero\n",
    "        print(f\"Error processing input: {e}\")\n",
    "        return 0.0\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-01-21T01:49:34.834549Z",
     "end_time": "2025-01-21T01:49:34.834549Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "def split_and_convert(value):\n",
    "    return list(map(int, value.strip(\"[\").strip(\"]\").replace(\",\", \" \").replace(\"-\",\" \").replace(\";\", \" \").replace(\":\", \" \").split()))\n",
    "\n",
    "def extract_code_file_type(df, type_value, actual_lines):\n",
    "    # Filter row based on 'type'\n",
    "    _row = df[df['type'] == type_value]\n",
    "\n",
    "    if row.empty:\n",
    "        return \"Type not found\"\n",
    "\n",
    "    try:\n",
    "        # Convert the actual_lines string to a list of integers\n",
    "        actual_lines_list = split_and_convert(actual_lines)\n",
    "\n",
    "        # Convert 'slice' and 'full' columns to lists of integers\n",
    "        slice_list = split_and_convert(_row.iloc[0]['slice'])\n",
    "        full_list = split_and_convert(_row.iloc[0]['full'])\n",
    "\n",
    "        # Check for exact matches\n",
    "        slice_match = set(slice_list) == set(actual_lines_list)\n",
    "        full_match = set(full_list) == set(actual_lines_list)\n",
    "\n",
    "        # Determine which column matches exactly\n",
    "        if slice_match:\n",
    "            return 'slice'\n",
    "        elif full_match:\n",
    "            return 'full'\n",
    "        else:\n",
    "            return 'NaN'\n",
    "    except ValueError as e:\n",
    "        print(f\"Error processing input: {e}\")\n",
    "        return 'NaN'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-01-21T01:49:35.007499Z",
     "end_time": "2025-01-21T01:49:35.007499Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2 code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing input: invalid literal for int() with base 10: 'The'\n"
     ]
    }
   ],
   "source": [
    "for index, row in df_responses.iterrows():\n",
    "    respondent_id = row['ResponseId']\n",
    "    duration_of_experiment = row['Duration (in seconds)']\n",
    "    which_group = row['Which Group']\n",
    "    exp_coding = row['Coder Experience']\n",
    "    exp_working_java = row['WorkingJava']\n",
    "    exp_finding_vuln = row['FindingVulns']\n",
    "\n",
    "    total_correctness_slice = 0.0\n",
    "    slice_count = 0\n",
    "    total_correctness_full = 0.0\n",
    "    full_count = 0\n",
    "\n",
    "    actual_lines_row = df_ground_truth[df_ground_truth['Groupnr'] == which_group]\n",
    "\n",
    "    # path\n",
    "    path_lines = str(row['PathLines'])\n",
    "    path_actual_lines = str(actual_lines_row.iloc[0]['Path']) # don't put in columns\n",
    "    path_lines_correctness = calc_lines_correctness(path_actual_lines, path_lines)\n",
    "    path_lines_type = extract_code_file_type(df_gt_code_lines, 'path', path_actual_lines)\n",
    "    if path_lines_type == 'slice':\n",
    "        slice_count += 1\n",
    "        total_correctness_slice += path_lines_correctness\n",
    "    elif path_lines_type == 'full':\n",
    "        full_count += 1\n",
    "        total_correctness_full += path_lines_correctness\n",
    "    path_motivation = row['PathMotivation']\n",
    "    path_difficulty = difficulties_list.index(row[\"Difficulty.Marks_1\"].lower()) + 1\n",
    "    path_confidence = confidence_list.index(row[\"Difficulty.Correct_1\"].lower()) + 1\n",
    "\n",
    "    # userinjection\n",
    "    userinjection_lines = str(row['InjectionLines'])\n",
    "    userinjection_actual_lines = str(actual_lines_row.iloc[0]['User']) # don't put in columns\n",
    "    userinjection_lines_correctness = calc_lines_correctness(userinjection_actual_lines, userinjection_lines)\n",
    "    userinjection_lines_type = extract_code_file_type(df_gt_code_lines, 'user', userinjection_actual_lines)\n",
    "    if userinjection_lines_type == 'slice':\n",
    "        slice_count += 1\n",
    "        total_correctness_slice += userinjection_lines_correctness\n",
    "    elif userinjection_lines_type == 'full':\n",
    "        full_count += 1\n",
    "        total_correctness_full += userinjection_lines_correctness\n",
    "    userinjection_motivation = row['InjectionMotivation']\n",
    "    userinjection_difficulty = difficulties_list.index(row[\"Difficulty.Marks_2\"].lower()) + 1\n",
    "    userinjection_confidence = confidence_list.index(row[\"Difficulty.Correct_2\"].lower()) + 1\n",
    "\n",
    "    # xss\n",
    "    xss_lines = str(row['XSSLines'])\n",
    "    xss_actual_lines = str(actual_lines_row.iloc[0]['XSS']) # don't put in columns\n",
    "    xss_lines_correctness = calc_lines_correctness(xss_actual_lines, xss_lines)\n",
    "    xss_lines_type = extract_code_file_type(df_gt_code_lines, 'xss', xss_actual_lines)\n",
    "    if xss_lines_type == 'slice':\n",
    "        slice_count += 1\n",
    "        total_correctness_slice += xss_lines_correctness\n",
    "    elif xss_lines_type == 'full':\n",
    "        full_count += 1\n",
    "        total_correctness_full += xss_lines_correctness\n",
    "    xss_motivation = row['XSSMotivation']\n",
    "    xss_difficulty = difficulties_list.index(row[\"Difficulty.Marks_3\"].lower()) + 1\n",
    "    xss_confidence = confidence_list.index(row[\"Difficulty.Correct_3\"].lower()) + 1\n",
    "\n",
    "    # dos\n",
    "    dos_lines = str(row['DoSLines'])\n",
    "    dos_actual_lines = str(actual_lines_row.iloc[0]['DoS']) # don't put in columns\n",
    "    dos_lines_correctness = calc_lines_correctness(dos_actual_lines, dos_lines)\n",
    "    dos_lines_type = extract_code_file_type(df_gt_code_lines, 'dos', dos_actual_lines)\n",
    "    if dos_lines_type == 'slice':\n",
    "        slice_count += 1\n",
    "        total_correctness_slice += dos_lines_correctness\n",
    "    elif dos_lines_type == 'full':\n",
    "        full_count += 1\n",
    "        total_correctness_full += dos_lines_correctness\n",
    "    dos_motivation = row['DoSMotivation']\n",
    "    dos_difficulty = difficulties_list.index(row[\"Difficulty.Marks_4\"].lower()) + 1\n",
    "    dos_confidence = confidence_list.index(row[\"Difficulty.Correct_4\"].lower()) + 1\n",
    "\n",
    "\n",
    "    familiar_java = row[\"Familiar.Java\"]\n",
    "    familiar_vuln = row[\"Familiar.Vuln\"]\n",
    "    proc_understand = row[\"Process.Understand\"]\n",
    "    proc_time = row[\"Process.Time\"]\n",
    "    proc_training = row[\"Process.Training\"]\n",
    "\n",
    "    avg_correctness_slice = None\n",
    "    avg_correctness_full = None\n",
    "\n",
    "\n",
    "    if slice_count > 0:\n",
    "        avg_correctness_slice = total_correctness_slice / slice_count\n",
    "\n",
    "    if full_count > 0:\n",
    "        avg_correctness_full = total_correctness_full / full_count\n",
    "\n",
    "    data_to_add = [\n",
    "        respondent_id, duration_of_experiment, which_group, exp_coding, exp_working_java, exp_finding_vuln,\n",
    "        path_lines, path_lines_correctness, path_lines_type, path_motivation, path_difficulty, path_confidence,\n",
    "        userinjection_lines, userinjection_lines_correctness, userinjection_lines_type, userinjection_motivation, userinjection_difficulty, userinjection_confidence,\n",
    "        xss_lines, xss_lines_correctness, xss_lines_type, xss_motivation, xss_difficulty, xss_confidence,\n",
    "        dos_lines, dos_lines_correctness, dos_lines_type, dos_motivation, dos_difficulty, dos_confidence,\n",
    "        familiar_java, familiar_vuln, proc_understand, proc_time, proc_training,\n",
    "        avg_correctness_slice, avg_correctness_full\n",
    "    ]\n",
    "    new_df.loc[len(new_df)] = data_to_add\n",
    "\n",
    "\n",
    "new_df.to_csv(responses_step2_file, index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-01-21T01:49:38.254076Z",
     "end_time": "2025-01-21T01:49:38.254076Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-01-21T01:49:38.263563Z",
     "end_time": "2025-01-21T01:49:38.263563Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
